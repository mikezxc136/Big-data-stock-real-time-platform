import datetime
import json
import threading
import time

import mysql.connector
import pandas as pd
import yfinance as yf

from kafka import KafkaConsumer, KafkaProducer

# Path to the CSV file containing tickers
CSV_FILE_PATH = 'D:\\Github Mikezxc\\Big-data-stock-real-time-platform\\kafka\\modeling\\tickers.csv'

# Hàm để lấy dữ liệu cổ phiếu
def fetch_stock_data(ticker, start_date, end_date, interval='1d'):
    stock = yf.Ticker(ticker)
    data = stock.history(start=start_date, end=end_date, interval=interval)
    data.reset_index(inplace=True)
    return data

# Hàm để gửi dữ liệu vào Kafka
def send_to_kafka(data, producer, topic, ticker):
    for index, row in data.iterrows():
        datetime_key = 'Datetime' if 'Datetime' in row else 'Date'
        message = {
            'Ticker': ticker,
            'Datetime': row[datetime_key].strftime('%Y-%m-%d %H:%M:%S'),
            'Open': float(row['Open']),
            'High': float(row['High']),
            'Low': float(row['Low']),
            'Close': float(row['Close']),
            'Volume': int(row['Volume'])
        }
        producer.send(topic, value=message)
        producer.flush()
    if not data.empty:
        update_last_processed_time(ticker, data[datetime_key].max())

def update_last_processed_time(ticker, last_processed_time):
    conn = mysql.connector.connect(
        user='mike',
        password='123',
        host='localhost',
        database='stock_stream'
    )
    cursor = conn.cursor()
    query = """
    INSERT INTO ticker_status (Ticker, LastProcessedTime)
    VALUES (%s, %s)
    ON DUPLICATE KEY UPDATE
        LastProcessedTime = VALUES(LastProcessedTime)
    """
    cursor.execute(query, (ticker, last_processed_time))
    conn.commit()
    cursor.close()
    conn.close()

def get_last_processed_time(ticker):
    conn = mysql.connector.connect(
        user='mike',
        password='123',
        host='localhost',
        database='stock_stream'
    )
    cursor = conn.cursor()
    query = "SELECT LastProcessedTime FROM ticker_status WHERE Ticker = %s"
    cursor.execute(query, (ticker,))
    result = cursor.fetchone()
    cursor.close()
    conn.close()
    return result[0] if result else None

# Hàm để tạo database và bảng nếu chưa tồn tại
def create_database_and_table():
    conn = mysql.connector.connect(
            user='mike',
            password='123',
            host='localhost',
            port='3306'
    )
    cursor = conn.cursor()
    
    cursor.execute("CREATE DATABASE IF NOT EXISTS stock_stream")
    cursor.execute("USE stock_stream")
    cursor.execute("""
    CREATE TABLE IF NOT EXISTS stock_data (
        id INT AUTO_INCREMENT PRIMARY KEY,
        Ticker VARCHAR(10),
        Datetime DATETIME,
        Open FLOAT,
        High FLOAT,
        Low FLOAT,
        Close FLOAT,
        Volume INT
    )
    """)
    cursor.execute("""
    CREATE TABLE IF NOT EXISTS ticker_status (
        Ticker VARCHAR(10) PRIMARY KEY,
        LastProcessedTime DATETIME
    )
    """)
    
    conn.commit()
    cursor.close()
    conn.close()

# Hàm để chèn dữ liệu vào MySQL
def insert_data(data):
    conn = mysql.connector.connect(
        user='mike',
        password='123',
        host='localhost',
        database='stock_stream'
    )
    cursor = conn.cursor()

    # Check if the record already exists
    query = """
    SELECT COUNT(*) FROM stock_data
    WHERE Ticker = %s AND Datetime = %s
    """
    cursor.execute(query, (data['Ticker'], data['Datetime']))
    count = cursor.fetchone()[0]

    if count == 0:
        # If the record does not exist, insert it
        query = """
        INSERT INTO stock_data (Ticker, Datetime, Open, High, Low, Close, Volume)
        VALUES (%s, %s, %s, %s, %s, %s, %s)
        ON DUPLICATE KEY UPDATE
            Open = VALUES(Open),
            High = VALUES(High),
            Low = VALUES(Low),
            Close = VALUES(Close),
            Volume = VALUES(Volume)
        """
        values = (
            data['Ticker'],
            data['Datetime'],
            data['Open'],
            data['High'],
            data['Low'],
            data['Close'],
            data['Volume']
        )

        cursor.execute(query, values)
        conn.commit()

    cursor.close()
    conn.close()

# Hàm tiêu thụ dữ liệu từ Kafka và chèn vào MySQL
def consume_messages():
    try:
        consumer = KafkaConsumer(
            'stock_topic',
            bootstrap_servers='localhost:9092',
            auto_offset_reset='latest',
            enable_auto_commit=True,
            group_id='my-group',
            value_deserializer=lambda x: json.loads(x.decode('utf-8'))
        )
        for message in consumer:
            print("Received message:", message.value)  # Thêm dòng này để kiểm tra dữ liệu nhận được
            try:
                insert_data(message.value)
            except KeyError as e:
                print(f"KeyError: {e} in message {message.value}")
            except Exception as e:
                print(f"Error inserting data: {e}")
    except Exception as e:
        print(f"Error setting up Kafka consumer: {e}")

# Hàm để đọc dữ liệu từ MySQL và gửi tới Kafka khác
def stream_mysql_to_kafka():
    conn = mysql.connector.connect(
        user='mike',
        password='123',
        host='localhost',
        database='stock_stream'
    )
    cursor = conn.cursor(dictionary=True)
    
    query = "SELECT * FROM stock_data"
    cursor.execute(query)
    rows = cursor.fetchall()
    
    producer = KafkaProducer(
        bootstrap_servers='localhost:9092',  # Sử dụng cùng Kafka cluster
        value_serializer=lambda v: json.dumps(v).encode('utf-8')
    )
    
    for row in rows:
        producer.send('mysql-to-postgres', value=row)
        producer.flush()
    
    cursor.close()
    conn.close()

# Hàm để xác minh dữ liệu đã được stream tới topic mới của Kafka
def verify_streamed_data():
    consumer = KafkaConsumer(
        'mysql-to-postgres',
        bootstrap_servers='localhost:9092',
        auto_offset_reset='earliest',
        enable_auto_commit=True,
        group_id='verification-group',
        value_deserializer=lambda x: json.loads(x.decode('utf-8'))
    )

    print("Listening to 'mysql-to-postgres' topic...")
    for message in consumer:
        print(f"Received message: {message.value}")

# Hàm chính
def main():
    # Thiết lập Kafka producer
    producer = KafkaProducer(
        bootstrap_servers='localhost:9092',
        value_serializer=lambda v: json.dumps(v).encode('utf-8')
    )

    # Tạo database và bảng nếu chưa tồn tại
    create_database_and_table()

    # Tạo một thread để tiêu thụ dữ liệu từ Kafka và chèn vào MySQL
    consumer_thread = threading.Thread(target=consume_messages, daemon=True)
    consumer_thread.start()

    # Đọc file CSV để lấy danh sách ticker
    tickers_df = pd.read_csv(CSV_FILE_PATH)
    tickers = tickers_df['Ticker'].tolist()

    # Lấy dữ liệu cổ phiếu và gửi vào Kafka
    end_date = datetime.datetime.now()

    for ticker in tickers:
        last_processed_time = get_last_processed_time(ticker)
        start_date = last_processed_time if last_processed_time else datetime.datetime(2015, 1, 1)
        historical_data = fetch_stock_data(ticker, start_date, end_date, interval='1d')
        send_to_kafka(historical_data, producer, 'stock_topic', ticker)

    # Continue fetching recent data in 1-minute intervals
    while True:
        try:
            current_time = datetime.datetime.now()
            recent_start_time = current_time - datetime.timedelta(days=1)
            for ticker in tickers:
                recent_data = fetch_stock_data(ticker, recent_start_time, current_time, interval='1m')
                if not recent_data.empty:
                    send_to_kafka(recent_data, producer, 'stock_topic', ticker)
            time.sleep(600)  # Đợi 10 phút trước khi lấy dữ liệu mới
        except Exception as e:
            print(f"Error fetching or sending data: {e}")

    # Tạo một thread để xác minh dữ liệu đã được stream tới topic mới của Kafka
    verification_thread = threading.Thread(target=verify_streamed_data, daemon=True)
    verification_thread.start()

if __name__ == "__main__":
    main()
